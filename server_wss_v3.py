from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request, HTTPException
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from starlette.status import HTTP_422_UNPROCESSABLE_ENTITY
from pydantic_settings import BaseSettings
from pydantic import BaseModel, Field
from funasr import AutoModel
import numpy as np
import soundfile as sf
import argparse
import uvicorn
from urllib.parse import parse_qs
import os
import re
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks
from loguru import logger
import sys
import json
import traceback
import time
from difflib import SequenceMatcher
from collections import defaultdict
import scipy.signal as signal
from scipy.signal import butter, lfilter, wiener

logger.remove()
log_format = "{time:YYYY-MM-DD HH:mm:ss} [{level}] {file}:{line} - {message}"
logger.add(sys.stdout, format=log_format, level="DEBUG", filter=lambda record: record["level"].no < 40)
logger.add(sys.stderr, format=log_format, level="ERROR", filter=lambda record: record["level"].no >= 40)


class Config(BaseSettings):
    sd_thr: float = Field(0.25, description="è¯´è¯äººåˆ†ç¦»ç›¸ä¼¼åº¦é˜ˆå€¼")  # é™ä½é˜ˆå€¼ï¼Œé¿å…åŒä¸€äººè¢«è¯†åˆ«æˆå¤šäºº
    chunk_size_ms: int = Field(300, description="åˆ†ç‰‡å¤§å°ï¼ˆæ¯«ç§’ï¼‰")
    sample_rate: int = Field(16000, description="é‡‡æ ·ç‡ï¼ˆHzï¼‰")
    bit_depth: int = Field(16, description="ä½æ·±")
    channels: int = Field(1, description="å£°é“æ•°")
    avg_logprob_thr: float = Field(-0.25, description="å¹³å‡å¯¹æ•°æ¦‚ç‡é˜ˆå€¼")
    min_confidence: float = Field(0.6, description="æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼")
    enable_error_correction: bool = Field(True, description="å¯ç”¨é”™è¯¯ä¿®æ­£")
    filter_noise_words: bool = Field(True, description="è¿‡æ»¤å™ªéŸ³è¯¯è¯†åˆ«è¯")
    min_text_length: int = Field(2, description="æœ€å°æœ‰æ•ˆæ–‡æœ¬é•¿åº¦")
    enable_audio_denoise: bool = Field(True, description="å¯ç”¨éŸ³é¢‘é™å™ª")
    denoise_method: str = Field("spectral", description="é™å™ªæ–¹æ³•: spectral/wiener/bandpass")
    noise_reduce_strength: float = Field(0.5, description="é™å™ªå¼ºåº¦(0.0-1.0)")

config = Config()

emo_dict = {
	"<|HAPPY|>": "",
	"<|SAD|>": "",
	"<|ANGRY|>": "",
	"<|NEUTRAL|>": "",
	"<|FEARFUL|>": "",
	"<|DISGUSTED|>": "",
	"<|SURPRISED|>": "",
}

event_dict = {
	"<|BGM|>": "",
	"<|Speech|>": "",
	"<|Applause|>": "",
	"<|Laughter|>": "",
	"<|Cry|>": "",
	"<|Sneeze|>": "",
	"<|Breath|>": "",
	"<|Cough|>": "",
}

emoji_dict = {
	"<|nospeech|><|Event_UNK|>": "",
	"<|zh|>": "",
	"<|en|>": "",
	"<|yue|>": "",
	"<|ja|>": "",
	"<|ko|>": "",
	"<|nospeech|>": "",
	"<|HAPPY|>": "",
	"<|SAD|>": "",
	"<|ANGRY|>": "",
	"<|NEUTRAL|>": "",
	"<|BGM|>": "",
	"<|Speech|>": "",
	"<|Applause|>": "",
	"<|Laughter|>": "",
	"<|FEARFUL|>": "",
	"<|DISGUSTED|>": "",
	"<|SURPRISED|>": "",
	"<|Cry|>": "",
	"<|EMO_UNKNOWN|>": "",
	"<|Sneeze|>": "",
	"<|Breath|>": "",
	"<|Cough|>": "",
	"<|Sing|>": "",
	"<|Speech_Noise|>": "",
	"<|withitn|>": "",
	"<|woitn|>": "",
	"<|GBG|>": "",
	"<|Event_UNK|>": "",
}

lang_dict =  {
    "<|zh|>": "<|lang|>",
    "<|en|>": "<|lang|>",
    "<|yue|>": "<|lang|>",
    "<|ja|>": "<|lang|>",
    "<|ko|>": "<|lang|>",
    "<|nospeech|>": "<|lang|>",
}

emo_set = {"ğŸ˜Š", "ğŸ˜”", "ğŸ˜¡", "ğŸ˜°", "ğŸ¤¢", "ğŸ˜®"}
event_set = {"ğŸ¼", "ğŸ‘", "ğŸ˜€", "ğŸ˜­", "ğŸ¤§", "ğŸ˜·",}

def format_str(s):
	for sptk in emoji_dict:
		s = s.replace(sptk, emoji_dict[sptk])
	return s


def format_str_v2(s):
	sptk_dict = {}
	for sptk in emoji_dict:
		sptk_dict[sptk] = s.count(sptk)
		s = s.replace(sptk, "")
	emo = "<|NEUTRAL|>"
	for e in emo_dict:
		if sptk_dict[e] > sptk_dict[emo]:
			emo = e
	for e in event_dict:
		if sptk_dict[e] > 0:
			s = event_dict[e] + s
	s = s + emo_dict[emo]

	for emoji in emo_set.union(event_set):
		s = s.replace(" " + emoji, emoji)
		s = s.replace(emoji + " ", emoji)
	return s.strip()

def format_str_v3(s):
	def get_emo(s):
		return s[-1] if s[-1] in emo_set else None
	def get_event(s):
		return s[0] if s[0] in event_set else None

	s = s.replace("<|nospeech|><|Event_UNK|>", "â“")
	for lang in lang_dict:
		s = s.replace(lang, "<|lang|>")
	s_list = [format_str_v2(s_i).strip(" ") for s_i in s.split("<|lang|>")]
	new_s = " " + s_list[0]
	cur_ent_event = get_event(new_s)
	for i in range(1, len(s_list)):
		if len(s_list[i]) == 0:
			continue
		if get_event(s_list[i]) == cur_ent_event and get_event(s_list[i]) != None:
			s_list[i] = s_list[i][1:]
		#else:
		cur_ent_event = get_event(s_list[i])
		if get_emo(s_list[i]) != None and get_emo(s_list[i]) == get_emo(new_s):
			new_s = new_s[:-1]
		new_s += s_list[i].strip().lstrip()
	new_s = new_s.replace("The.", " ")
	return new_s.strip()

def contains_chinese_english_number(s: str) -> bool:
    # Check if the string contains any Chinese character, English letter, or Arabic number
    return bool(re.search(r'[\u4e00-\u9fffA-Za-z0-9]', s))


# ============ éŸ³é¢‘é™å™ªæ¨¡å— ============

class AudioDenoiser:
    """
    éŸ³é¢‘é™å™ªå™¨,ç”¨äºåœ¨ASRè¯†åˆ«å‰å¯¹éŸ³é¢‘ä¿¡å·è¿›è¡Œé™å™ªå¤„ç†
    æ”¯æŒå¤šç§é™å™ªç®—æ³•:
    1. é¢‘è°±å‡æ³•(Spectral Subtraction)
    2. ç»´çº³æ»¤æ³¢(Wiener Filter)
    3. å¸¦é€šæ»¤æ³¢(Bandpass Filter)
    """
    
    def __init__(self, sample_rate=16000):
        self.sample_rate = sample_rate
        # è¯­éŸ³é¢‘ç‡èŒƒå›´: 300Hz - 3400Hz
        self.speech_lowcut = 300.0
        self.speech_highcut = 3400.0
        
    def butter_bandpass(self, lowcut, highcut, fs, order=5):
        """
        è®¾è®¡å¸¦é€šæ»¤æ³¢å™¨
        """
        nyq = 0.5 * fs
        low = lowcut / nyq
        high = highcut / nyq
        b, a = butter(order, [low, high], btype='band')
        return b, a
    
    def bandpass_filter(self, data, lowcut, highcut, fs, order=5):
        """
        åº”ç”¨å¸¦é€šæ»¤æ³¢
        """
        b, a = self.butter_bandpass(lowcut, highcut, fs, order=order)
        y = lfilter(b, a, data)
        return y
    
    def spectral_subtraction(self, audio, noise_profile=None, strength=0.5):
        """
        é¢‘è°±å‡æ³•é™å™ª
        
        Args:
            audio: éŸ³é¢‘ä¿¡å·
            noise_profile: å™ªå£°é¢‘è°±(å¦‚æœä¸ºNone,ä½¿ç”¨å‰10%ä½œä¸ºå™ªå£°ä¼°è®¡)
            strength: é™å™ªå¼ºåº¦(0.0-1.0)
        """
        # è®¡ç®—FFT
        fft_audio = np.fft.rfft(audio)
        power_spectrum = np.abs(fft_audio) ** 2
        
        # ä¼°è®¡å™ªå£°é¢‘è°±(ä½¿ç”¨å‰10%çš„éŸ³é¢‘)
        if noise_profile is None:
            noise_len = len(audio) // 10
            noise_audio = audio[:noise_len]
            fft_noise = np.fft.rfft(noise_audio)
            noise_power = np.abs(fft_noise) ** 2
            # æ‰©å±•åˆ°ä¸éŸ³é¢‘ç›¸åŒé•¿åº¦
            noise_profile = np.mean(noise_power) * np.ones_like(power_spectrum)
        
        # é¢‘è°±å‡æ³•
        clean_power = power_spectrum - strength * noise_profile
        clean_power = np.maximum(clean_power, 0.1 * power_spectrum)  # é¿å…è¿‡åº¦å‡æ³•
        
        # é‡å»ºä¿¡å·
        phase = np.angle(fft_audio)
        clean_fft = np.sqrt(clean_power) * np.exp(1j * phase)
        clean_audio = np.fft.irfft(clean_fft, n=len(audio))
        
        return clean_audio.astype(np.float32)
    
    def wiener_filter_denoise(self, audio, noise_power=None):
        """
        ç»´çº³æ»¤æ³¢é™å™ª
        """
        try:
            # ä½¿ç”¨scipyçš„wieneræ»¤æ³¥
            denoised = wiener(audio)
            return denoised.astype(np.float32)
        except Exception as e:
            logger.warning(f"[ç»´çº³æ»¤æ³¢] å¤±è´¥: {e}, è¿”å›åŸå§‹éŸ³é¢‘")
            return audio
    
    def energy_based_filter(self, audio, threshold_percentile=20):
        """
        åŸºäºèƒ½é‡çš„ç®€å•é™å™ª
        å°†ä½èƒ½é‡å¸§è®¾ä¸ºé›¶(å¯èƒ½æ˜¯å™ªå£°)
        """
        # è®¡ç®—çŸ­æ—¶èƒ½é‡
        frame_length = 400  # 25ms @ 16kHz
        hop_length = 160    # 10ms @ 16kHz
        
        energy = []
        for i in range(0, len(audio) - frame_length, hop_length):
            frame = audio[i:i+frame_length]
            energy.append(np.sum(frame ** 2))
        
        if len(energy) == 0:
            return audio
        
        # è®¡ç®—èƒ½é‡é˜ˆå€¼
        threshold = np.percentile(energy, threshold_percentile)
        
        # åº”ç”¨é˜ˆå€¼
        denoised = audio.copy()
        for i, e in enumerate(energy):
            if e < threshold:
                start = i * hop_length
                end = start + frame_length
                if end <= len(denoised):
                    denoised[start:end] *= 0.1  # è¡°å‡ä½†ä¸å®Œå…¨æ¶ˆé™¤
        
        return denoised
    
    def denoise(self, audio, method="spectral", strength=0.5):
        """
        å¯¹éŸ³é¢‘è¿›è¡Œé™å™ªå¤„ç†
        
        Args:
            audio: éŸ³é¢‘ä¿¡å·(numpy array)
            method: é™å™ªæ–¹æ³• ("spectral", "wiener", "bandpass", "energy")
            strength: é™å™ªå¼ºåº¦(0.0-1.0)
        
        Returns:
            denoised_audio: é™å™ªåçš„éŸ³é¢‘
        """
        if len(audio) == 0:
            return audio
        
        try:
            if method == "spectral":
                # é¢‘è°±å‡æ³•
                denoised = self.spectral_subtraction(audio, strength=strength)
                logger.debug(f"[éŸ³é¢‘é™å™ª] ä½¿ç”¨é¢‘è°±å‡æ³•,å¼ºåº¦={strength}")
            
            elif method == "wiener":
                # ç»´çº³æ»¤æ³¢
                denoised = self.wiener_filter_denoise(audio)
                logger.debug(f"[éŸ³é¢‘é™å™ª] ä½¿ç”¨ç»´çº³æ»¤æ³¢")
            
            elif method == "bandpass":
                # å¸¦é€šæ»¤æ³¢
                denoised = self.bandpass_filter(
                    audio, 
                    self.speech_lowcut, 
                    self.speech_highcut, 
                    self.sample_rate
                )
                logger.debug(f"[éŸ³é¢‘é™å™ª] ä½¿ç”¨å¸¦é€šæ»¤æ³¢ {self.speech_lowcut}-{self.speech_highcut}Hz")
            
            elif method == "energy":
                # èƒ½é‡é˜ˆå€¼æ³•
                denoised = self.energy_based_filter(audio)
                logger.debug(f"[éŸ³é¢‘é™å™ª] ä½¿ç”¨èƒ½é‡é˜ˆå€¼æ³•")
            
            else:
                logger.warning(f"[éŸ³é¢‘é™å™ª] æœªçŸ¥æ–¹æ³•: {method}, è¿”å›åŸå§‹éŸ³é¢‘")
                return audio
            
            # ç¡®ä¿è¾“å‡ºèŒƒå›´åœ¨[-1, 1]
            denoised = np.clip(denoised, -1.0, 1.0)
            
            return denoised
            
        except Exception as e:
            logger.error(f"[éŸ³é¢‘é™å™ª] å¤±è´¥: {e}")
            return audio


# åˆå§‹åŒ–éŸ³é¢‘é™å™ªå™¨
audio_denoiser = AudioDenoiser(sample_rate=16000)


# ============ ASRé”™è¯¯ä¿®æ­£æ¨¡å— ============

class ASRErrorCorrector:
    """
    ASRé”™è¯¯ä¿®æ­£å™¨,ç”¨äºä¿®æ­£ä¸‰ç§å¸¸è§é”™è¯¯:
    1. æ›¿æ¢é”™è¯¯(Substitution): åŒéŸ³å­—ã€å½¢è¿‘å­—
    2. æ’å…¥é”™è¯¯(Insertion): å¤šä½™çš„è¯­æ°”è¯ã€é‡å¤å­—
    3. åˆ é™¤é”™è¯¯(Deletion): ç¼ºå¤±çš„å­—è¯
    """
    
    def __init__(self):
        # åŒéŸ³å­—æ›¿æ¢è¯å…¸(æ›¿æ¢é”™è¯¯)
        self.homophone_dict = {
            "å°å³": "å°ä½‘",
            "å°ä¼˜": "å°ä½‘",
            "å°æœ‰": "å°ä½‘",
            "åœ¨é‚£": "å†æ‹¿",
            "åœ¨æ‹¿": "å†æ‹¿",
            "çš„è¯": "å¾—è¯",
            "åšåˆ°": "åšåˆ°",
            "åœ¨è§": "å†è§",
            "åœ¨ä¼š": "å†ä¼š",
            # å¯ä»¥ç»§ç»­æ·»åŠ æ›´å¤šåŒéŸ³å­—è§„åˆ™
        }
        
        # ä¸“æœ‰åè¯è¯å…¸(æ›¿æ¢é”™è¯¯)
        self.proper_noun_dict = {
            "é˜¿é‡Œå·´å·´": ["é˜¿é‡Œçˆ¸çˆ¸", "é˜¿é‡Œå§å§"],
            "è…¾è®¯": ["è…¾ä¿¡", "è…¾è®¯"],
            "ChatGPT": ["chat gpt", "chatgpt", "chat GPT"],
            "SenseVoice": ["sense voice", "sensevoice"],
            # å¯ä»¥ç»§ç»­æ·»åŠ æ›´å¤šä¸“æœ‰åè¯
        }
        
        # å¸¸è§æ’å…¥é”™è¯¯(è¯­æ°”è¯ã€é‡å¤)
        self.insertion_patterns = [
            r'(.)\1{2,}',  # è¿ç»­é‡å¤3æ¬¡ä»¥ä¸Šçš„å­—ç¬¦
            r'(å‘ƒ|å•Š|å—¯|å“¦){2,}',  # é‡å¤çš„è¯­æ°”è¯
        ]
        
        # å™ªéŸ³è¯¯è¯†åˆ«è¯åˆ—è¡¨(é€šå¸¸æ˜¯å•ä¸ªå­—æˆ–è¯­æ°”è¯)
        self.noise_words = {
            "å—¯", "å•Š", "å‘ƒ", "å“¦", "å””", "å˜›", "å‘¢", "å“ª",
            "é¢", "è¯¶", "å“", "å˜¿", "å–‚", "å’¦", "å“Ÿ", "å—¨",
            "å˜˜", "å’³", "å“¼", "å—³", "å“‡", "å™¢", "å—·", "å’¿",
            # å•ä¸ªæ ‡ç‚¹æˆ–æ— æ„ä¹‰å­—ç¬¦
            "ã€‚", "ï¼Œ", "ã€", "ï¼Ÿ", "ï¼", " ", "ã€€",
        }
        
        # å™ªéŸ³æ¨¡å¼(æ­£åˆ™è¡¨è¾¾å¼)
        self.noise_patterns = [
            r'^[å—¯å•Šå‘ƒå“¦å””å˜›å‘¢å“ªé¢è¯¶å“å˜¿å–‚å’¦å“Ÿå—¨]+$',  # çº¯è¯­æ°”è¯
            r'^[ã€‚ï¼Œã€ï¼Ÿï¼\s]+$',  # çº¯æ ‡ç‚¹
            r'^[a-zA-Z]$',  # å•ä¸ªè‹±æ–‡å­—æ¯
        ]
        
        # å¸¸è§åˆ é™¤é”™è¯¯çš„è¡¥å…¨è§„åˆ™
        self.completion_rules = {
            r'ä¸æ˜¯': 'ä¸æ˜¯å—',
            r'å¯ä»¥': 'å¯ä»¥çš„',
            r'æ²¡æœ‰': 'æ²¡æœ‰äº†',
        }
        
        # ä¸Šä¸‹æ–‡N-gramç»Ÿè®¡(ç”¨äºåŸºäºæ¦‚ç‡çš„ä¿®æ­£)
        self.bigram_freq = defaultdict(int)
        self.trigram_freq = defaultdict(int)
        
    def correct_homophones(self, text: str) -> str:
        """
        ä¿®æ­£åŒéŸ³å­—é”™è¯¯(æ›¿æ¢é”™è¯¯)
        """
        corrected = text
        for wrong, correct in self.homophone_dict.items():
            if wrong in corrected:
                corrected = corrected.replace(wrong, correct)
                logger.debug(f"[åŒéŸ³å­—ä¿®æ­£] '{wrong}' -> '{correct}'")
        return corrected
    
    def correct_proper_nouns(self, text: str) -> str:
        """
        ä¿®æ­£ä¸“æœ‰åè¯é”™è¯¯(æ›¿æ¢é”™è¯¯)
        """
        corrected = text
        for correct_noun, wrong_variants in self.proper_noun_dict.items():
            for wrong in wrong_variants:
                if wrong in corrected.lower():
                    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œå¤§å°å†™ä¸æ•æ„Ÿçš„æ›¿æ¢
                    pattern = re.compile(re.escape(wrong), re.IGNORECASE)
                    corrected = pattern.sub(correct_noun, corrected)
                    logger.debug(f"[ä¸“æœ‰åè¯ä¿®æ­£] '{wrong}' -> '{correct_noun}'")
        return corrected
    
    def is_noise_text(self, text: str, confidence: float = 1.0) -> bool:
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºå™ªéŸ³è¯¯è¯†åˆ«
        """
        if not text or len(text.strip()) == 0:
            return True
        
        text = text.strip()
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å™ªéŸ³è¯åˆ—è¡¨ä¸­
        if text in self.noise_words:
            return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…å™ªéŸ³æ¨¡å¼
        for pattern in self.noise_patterns:
            if re.match(pattern, text):
                return True
        
        # æ£€æŸ¥æ˜¯å¦åªåŒ…å«è¯­æ°”è¯å’Œæ ‡ç‚¹
        clean_text = re.sub(r'[å—¯å•Šå‘ƒå“¦å””å˜›å‘¢å“ªé¢è¯¶å“å˜¿å–‚å’¦å“Ÿå—¨ã€‚ï¼Œã€ï¼Ÿï¼\s]', '', text)
        if len(clean_text) == 0:
            return True
        
        # ç‰¹æ®Šæ£€æŸ¥: å•ä¸ªè¯­æ°”è¯+æ ‡ç‚¹(å¦‚"å—¯ã€‚"ã€"å•Š!")
        if len(text) <= 2:
            # ç§»é™¤æ ‡ç‚¹åæ£€æŸ¥
            text_no_punct = re.sub(r'[ã€‚ï¼Œã€ï¼Ÿï¼\s]', '', text)
            if text_no_punct in self.noise_words:
                return True
        
        # å•å­—+æ ‡ç‚¹çš„æƒ…å†µ,ç»“åˆç½®ä¿¡åº¦åˆ¤æ–­
        # ç§»é™¤æ ‡ç‚¹ååªæœ‰1ä¸ªå­—,ä¸”ç½®ä¿¡åº¦ä¸é«˜,å¯èƒ½æ˜¯å™ªéŸ³
        text_no_punct_final = re.sub(r'[ã€‚ï¼Œã€ï¼Ÿï¼\s]', '', text)
        if len(text_no_punct_final) == 1 and confidence < 0.85:
            logger.debug(f"[å™ªéŸ³æ£€æµ‹] å•å­—ä½ç½®ä¿¡åº¦: '{text}' (ç½®ä¿¡åº¦={confidence:.2f})")
            return True
        
        return False
    
    def remove_insertions(self, text: str) -> str:
        """
        ç§»é™¤æ’å…¥é”™è¯¯(å¤šä½™å­—ç¬¦)
        """
        corrected = text
        for pattern in self.insertion_patterns:
            matches = re.finditer(pattern, corrected)
            for match in matches:
                original = match.group(0)
                # ä¿ç•™ä¸€ä¸ªå­—ç¬¦,åˆ é™¤é‡å¤çš„
                replacement = match.group(1)
                corrected = corrected.replace(original, replacement, 1)
                logger.debug(f"[æ’å…¥é”™è¯¯ä¿®æ­£] åˆ é™¤é‡å¤: '{original}' -> '{replacement}'")
        return corrected
    
    def filter_noise(self, text: str, confidence: float = 1.0) -> tuple[str, bool]:
        """
        è¿‡æ»¤å™ªéŸ³è¯¯è¯†åˆ«çš„æ–‡æœ¬
        
        Returns:
            filtered_text: è¿‡æ»¤åçš„æ–‡æœ¬
            is_filtered: æ˜¯å¦è¢«è¿‡æ»¤
        """
        if self.is_noise_text(text, confidence):
            logger.info(f"[å™ªéŸ³è¿‡æ»¤] æ£€æµ‹åˆ°å™ªéŸ³æ–‡æœ¬: '{text}'")
            return "", True
        
        # ç§»é™¤æ–‡æœ¬å¼€å¤´å’Œç»“å°¾çš„è¯­æ°”è¯
        original = text
        text = re.sub(r'^[å—¯å•Šå‘ƒå“¦å””]+', '', text)
        text = re.sub(r'[å—¯å•Šå‘ƒå“¦å””]+$', '', text)
        
        if text != original:
            logger.debug(f"[å™ªéŸ³è¿‡æ»¤] ç§»é™¤é¦–å°¾è¯­æ°”è¯: '{original}' -> '{text}'")
        
        return text.strip(), False
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦(ç”¨äºæ£€æµ‹æ›¿æ¢é”™è¯¯)
        """
        return SequenceMatcher(None, str1, str2).ratio()
    
    def correct_by_context(self, text: str, prev_text: str = "") -> str:
        """
        åŸºäºä¸Šä¸‹æ–‡è¿›è¡Œä¿®æ­£(å¯ä»¥æ£€æµ‹åˆ é™¤é”™è¯¯)
        è¿™é‡Œä½¿ç”¨ç®€å•çš„è§„åˆ™,å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨è¯­è¨€æ¨¡å‹
        """
        corrected = text
        
        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘æ ‡ç‚¹ç¬¦å·(åˆ é™¤é”™è¯¯)
        if len(corrected) > 10 and not re.search(r'[,ã€‚!?ã€]', corrected):
            # ç®€å•è§„åˆ™:åœ¨å¥å­ä¸­é—´æ·»åŠ é€—å·
            mid_point = len(corrected) // 2
            corrected = corrected[:mid_point] + ',' + corrected[mid_point:]
            logger.debug(f"[åˆ é™¤é”™è¯¯ä¿®æ­£] æ·»åŠ æ ‡ç‚¹ç¬¦å·")
        
        return corrected
    
    def correct_text(self, text: str, prev_text: str = "", confidence: float = 1.0, filter_noise: bool = True) -> tuple[str, list[dict], bool]:
        """
        ç»¼åˆä¿®æ­£æ–‡æœ¬ä¸­çš„å„ç§é”™è¯¯
        
        Args:
            text: å¾…ä¿®æ­£çš„æ–‡æœ¬
            prev_text: å‰ä¸€å¥æ–‡æœ¬(ç”¨äºä¸Šä¸‹æ–‡åˆ†æ)
            confidence: è¯†åˆ«ç½®ä¿¡åº¦
            filter_noise: æ˜¯å¦è¿‡æ»¤å™ªéŸ³
        
        Returns:
            corrected_text: ä¿®æ­£åçš„æ–‡æœ¬
            corrections: ä¿®æ­£è®°å½•åˆ—è¡¨
            is_noise: æ˜¯å¦ä¸ºå™ªéŸ³(åº”è¯¥è¢«ä¸¢å¼ƒ)
        """
        original_text = text
        corrections = []
        
        # 0. å™ªéŸ³è¿‡æ»¤(æœ€ä¼˜å…ˆ)
        if filter_noise:
            text, is_filtered = self.filter_noise(text, confidence)
            if is_filtered:
                corrections.append({
                    "type": "noise_filter",
                    "original": original_text,
                    "corrected": "",
                    "method": "noise_detection"
                })
                return "", corrections, True  # æ ‡è®°ä¸ºå™ªéŸ³
            
            if text != original_text:
                corrections.append({
                    "type": "noise_filter",
                    "original": original_text,
                    "corrected": text,
                    "method": "remove_edge_noise"
                })
                original_text = text
        
        # 1. ä¿®æ­£åŒéŸ³å­—(æ›¿æ¢é”™è¯¯)
        text = self.correct_homophones(text)
        if text != original_text:
            corrections.append({
                "type": "substitution",
                "original": original_text,
                "corrected": text,
                "method": "homophone"
            })
            original_text = text
        
        # 2. ä¿®æ­£ä¸“æœ‰åè¯(æ›¿æ¢é”™è¯¯)
        text = self.correct_proper_nouns(text)
        if text != original_text:
            corrections.append({
                "type": "substitution",
                "original": original_text,
                "corrected": text,
                "method": "proper_noun"
            })
            original_text = text
        
        # 3. ç§»é™¤æ’å…¥é”™è¯¯
        text = self.remove_insertions(text)
        if text != original_text:
            corrections.append({
                "type": "insertion",
                "original": original_text,
                "corrected": text,
                "method": "remove_repetition"
            })
            original_text = text
        
        # 4. åŸºäºä¸Šä¸‹æ–‡ä¿®æ­£(å¯ä»¥æ£€æµ‹åˆ é™¤é”™è¯¯)
        if prev_text:
            text = self.correct_by_context(text, prev_text)
            if text != original_text:
                corrections.append({
                    "type": "deletion",
                    "original": original_text,
                    "corrected": text,
                    "method": "context"
                })
        
        # 5. æœ€ç»ˆæ£€æŸ¥:å¦‚æœä¿®æ­£åæ–‡æœ¬å¤ªçŸ­æˆ–ä¸ºç©º,æ ‡è®°ä¸ºå™ªéŸ³
        if filter_noise and len(text.strip()) < 1:
            return "", corrections, True
        
        return text, corrections, False


# åˆå§‹åŒ–é”™è¯¯ä¿®æ­£å™¨
error_corrector = ASRErrorCorrector()


# sv_pipeline = pipeline(
#     task='speaker-verification',
#     model='iic/speech_eres2net_large_sv_zh-cn_3dspeaker_16k',
#     model_revision='v1.0.0'
# )

# ============ æ¨¡å‹åŠ è½½é…ç½® ============
# ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜,é¿å…ç½‘ç»œé—®é¢˜

# 1. è¯´è¯äººåˆ†ç¦»æ¨¡å‹ - ç”¨äºæå–å£°çº¹ç‰¹å¾å’Œè¯´è¯äººè¯†åˆ«
sd_model_cache = os.path.expanduser('~/.cache/modelscope/hub/iic/speech_campplus_sv_zh-cn_16k-common')
if not os.path.exists(sd_model_cache):
    sd_model_cache = 'iic/speech_campplus_sv_zh-cn_16k-common'
    logger.warning(f"æœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨,å°†å°è¯•ä» ModelScope ä¸‹è½½: {sd_model_cache}")
else:
    logger.info(f"ä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„è¯´è¯äººåˆ†ç¦»æ¨¡å‹: {sd_model_cache}")

sd_pipeline = pipeline(
    task='speaker-verification',
    model=sd_model_cache,
    model_revision='v1.0.0' if sd_model_cache.startswith('iic/') else None
)

# 2. ASR æ¨¡å‹(ä½¿ç”¨å¾®è°ƒæƒé‡)
asr_model_cache = os.path.expanduser('~/.cache/modelscope/hub/iic/SenseVoiceSmall')
if not os.path.exists(asr_model_cache):
    asr_model_cache = "iic/SenseVoiceSmall"
    logger.warning(f"æœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨,å°†å°è¯•ä» ModelScope ä¸‹è½½: {asr_model_cache}")
else:
    logger.info(f"ä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„ ASR æ¨¡å‹: {asr_model_cache}")

# å…ˆåŠ è½½åŸå§‹æ¨¡å‹
model_asr = AutoModel(
    model=asr_model_cache,
    trust_remote_code=True,
    remote_code="./model.py",    
    device="cuda:0",
    disable_update=True,
    initial_model="./outputs/model.pt.avg10"  # åŠ è½½å¾®è°ƒåçš„å¹³å‡æƒé‡(æ¨è)
)

# 3. VAD æ¨¡å‹
vad_model_cache = os.path.expanduser('~/.cache/modelscope/hub/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch')
if not os.path.exists(vad_model_cache):
    vad_model_cache = "fsmn-vad"
    vad_model_revision = "v2.0.4"
    logger.warning(f"æœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨,å°†å°è¯•ä» ModelScope ä¸‹è½½: {vad_model_cache}")
else:
    vad_model_cache = vad_model_cache
    vad_model_revision = None
    logger.info(f"ä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„ VAD æ¨¡å‹: {vad_model_cache}")

model_vad = AutoModel(
    model=vad_model_cache,
    model_revision=vad_model_revision,
    disable_pbar=True,
    max_end_silence_time=500,
    # speech_noise_thres=0.6,
    disable_update=True,
)

# æ—§çš„é¢„æ³¨å†Œè¯´è¯äººéªŒè¯åŠŸèƒ½å·²ç§»é™¤ï¼Œç°åœ¨ä½¿ç”¨ identify_speaker() è¿›è¡ŒåŠ¨æ€è¯´è¯äººè¯†åˆ«


def extract_speaker_embedding(audio):
    """
    æå–éŸ³é¢‘çš„è¯´è¯äººå£°çº¹ç‰¹å¾å‘é‡
    """
    try:
        # ä½¿ç”¨è¯´è¯äººéªŒè¯æ¨¡å‹æå–å£°çº¹ç‰¹å¾
        result = sd_pipeline([audio, audio], 0.0)
        # è¿”å›å£°çº¹ç‰¹å¾(embedding)
        if 'emb' in result:
            return result['emb']
        else:
            # å¦‚æœæ²¡æœ‰ç›´æ¥è¿”å›embedding,ä½¿ç”¨æ¨¡å‹å†…éƒ¨æ–¹æ³•
            return sd_pipeline.model.forward(audio)
    except Exception as e:
        logger.error(f"[extract_speaker_embedding] æå–å£°çº¹ç‰¹å¾å¤±è´¥: {e}")
        return None


def compute_similarity(emb1, emb2):
    """
    è®¡ç®—ä¸¤ä¸ªå£°çº¹ç‰¹å¾å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
    """
    if emb1 is None or emb2 is None:
        return 0.0
    try:
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if not isinstance(emb1, np.ndarray):
            emb1 = np.array(emb1)
        if not isinstance(emb2, np.ndarray):
            emb2 = np.array(emb2)
        
        # å±•å¹³ä¸ºä¸€ç»´æ•°ç»„ï¼ˆå¤„ç† (1, 192) è¿™æ ·çš„äºŒç»´æ•°ç»„ï¼‰
        emb1 = emb1.flatten()
        emb2 = emb2.flatten()
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        dot_product = np.dot(emb1, emb2)
        norm1 = np.linalg.norm(emb1)
        norm2 = np.linalg.norm(emb2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        similarity = dot_product / (norm1 * norm2)
        return float(similarity)
    except Exception as e:
        logger.error(f"[compute_similarity] è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥: {e}")
        return 0.0


def identify_speaker(audio, speaker_embeddings, sd_thr):
    """
    è¯†åˆ«è¯´è¯äºº,è¿”å›è¯´è¯äººID
    
    Args:
        audio: éŸ³é¢‘æ•°æ®
        speaker_embeddings: å·²çŸ¥è¯´è¯äººçš„å£°çº¹ç‰¹å¾å­—å…¸ {speaker_id: embedding}
        sd_thr: ç›¸ä¼¼åº¦é˜ˆå€¼
    
    Returns:
        speaker_id: è¯´è¯äººID (speaker_1, speaker_2, ...)
        is_new: æ˜¯å¦æ˜¯æ–°è¯´è¯äºº
    """
    # æå–å½“å‰éŸ³é¢‘çš„å£°çº¹ç‰¹å¾
    current_emb = extract_speaker_embedding(audio)
    if current_emb is None:
        return None, False
    
    # å¦‚æœè¿˜æ²¡æœ‰æ³¨å†Œçš„è¯´è¯äºº,è¿™æ˜¯ç¬¬ä¸€ä¸ªè¯´è¯äºº
    if len(speaker_embeddings) == 0:
        speaker_id = "speaker_1"
        speaker_embeddings[speaker_id] = current_emb
        logger.info(f"[identify_speaker] æ³¨å†Œæ–°è¯´è¯äºº: {speaker_id}")
        return speaker_id, True
    
    # ä¸å·²çŸ¥è¯´è¯äººè¿›è¡Œæ¯”å¯¹
    max_similarity = -1
    matched_speaker = None
    
    for spk_id, spk_emb in speaker_embeddings.items():
        similarity = compute_similarity(current_emb, spk_emb)
        logger.debug(f"[identify_speaker] ä¸ {spk_id} çš„ç›¸ä¼¼åº¦: {similarity:.4f}")
        
        if similarity > max_similarity:
            max_similarity = similarity
            matched_speaker = spk_id
    
    # å¦‚æœæœ€å¤§ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼,è®¤ä¸ºæ˜¯å·²çŸ¥è¯´è¯äºº
    if max_similarity >= sd_thr:
        logger.info(f"[identify_speaker] è¯†åˆ«ä¸ºå·²çŸ¥è¯´è¯äºº: {matched_speaker}, ç›¸ä¼¼åº¦: {max_similarity:.4f}")
        return matched_speaker, False
    else:
        # å¦åˆ™æ³¨å†Œä¸ºæ–°è¯´è¯äºº
        new_speaker_id = f"speaker_{len(speaker_embeddings) + 1}"
        speaker_embeddings[new_speaker_id] = current_emb
        logger.info(f"[identify_speaker] æ³¨å†Œæ–°è¯´è¯äºº: {new_speaker_id}, æœ€å¤§ç›¸ä¼¼åº¦: {max_similarity:.4f}")
        return new_speaker_id, True


def asr(audio, lang, cache, use_itn=False, prev_text="", enable_correction=True, enable_denoise=True):
    """
    æ‰§è¡ŒASRè¯†åˆ«å¹¶è¿›è¡Œé”™è¯¯ä¿®æ­£
    
    Args:
        audio: éŸ³é¢‘æ•°æ®
        lang: è¯­è¨€
        cache: ç¼“å­˜
        use_itn: æ˜¯å¦ä½¿ç”¨ITN
        prev_text: å‰ä¸€å¥æ–‡æœ¬(ç”¨äºä¸Šä¸‹æ–‡ä¿®æ­£)
        enable_correction: æ˜¯å¦å¯ç”¨é”™è¯¯ä¿®æ­£
        enable_denoise: æ˜¯å¦å¯ç”¨éŸ³é¢‘é™å™ª
    
    Returns:
        result: ASRè¯†åˆ«ç»“æœ
    """
    start_time = time.time()
    
    # éŸ³é¢‘é™å™ªå¤„ç†
    if enable_denoise and config.enable_audio_denoise:
        denoise_start = time.time()
        audio = audio_denoiser.denoise(
            audio, 
            method=config.denoise_method,
            strength=config.noise_reduce_strength
        )
        denoise_elapsed = (time.time() - denoise_start) * 1000
        logger.debug(f"[éŸ³é¢‘é™å™ª] è€—æ—¶: {denoise_elapsed:.2f} ms")
    result = model_asr.generate(
        input           = audio,
        cache           = cache,
        language        = lang.strip(),
        use_itn         = use_itn,
        batch_size_s    = 60,
    )
    end_time = time.time()
    elapsed_time = end_time - start_time
    logger.debug(f"asr elapsed: {elapsed_time * 1000:.2f} milliseconds")
    
    # é”™è¯¯ä¿®æ­£å¤„ç†
    if result and len(result) > 0 and 'text' in result[0] and enable_correction:
        original_text = result[0]['text']
        
        # å…ˆç§»é™¤ç‰¹æ®Šæ ‡è®°,å¾—åˆ°çº¯æ–‡æœ¬
        clean_text = format_str_v3(original_text)
        logger.debug(f"[æ–‡æœ¬æ¸…ç†] åŸå§‹: '{original_text}' -> æ¸…ç†: '{clean_text}'")
        
        # è·å–ç½®ä¿¡åº¦(å¦‚æœæœ‰)
        confidence = 1.0
        if 'confidence' in result[0]:
            confidence = result[0]['confidence']
        elif 'avg_logprob' in result[0]:
            # å°†å¯¹æ•°æ¦‚ç‡è½¬æ¢ä¸ºç½®ä¿¡åº¦
            confidence = min(1.0, max(0.0, (result[0]['avg_logprob'] + 1.0)))
        
        # ä½¿ç”¨é”™è¯¯ä¿®æ­£å™¨å¯¹æ¸…ç†åçš„æ–‡æœ¬è¿›è¡Œä¿®æ­£
        corrected_text, corrections, is_noise = error_corrector.correct_text(
            clean_text,  # ä½¿ç”¨æ¸…ç†åçš„æ–‡æœ¬
            prev_text=prev_text,
            confidence=confidence,
            filter_noise=config.filter_noise_words
        )
        
        # å¦‚æœæ£€æµ‹åˆ°å™ªéŸ³,è¿”å›ç©ºç»“æœ
        if is_noise:
            logger.info(f"[å™ªéŸ³è¿‡æ»¤] ä¸¢å¼ƒå™ªéŸ³æ–‡æœ¬: '{clean_text}' (åŸå§‹: '{original_text}')")
            return None  # è¿”å› None è¡¨ç¤ºåº”è¯¥ä¸¢å¼ƒæ­¤ç»“æœ
        
        # æ›´æ–°ç»“æœ(ä½¿ç”¨ä¿®æ­£åçš„æ–‡æœ¬é‡æ–°æ„å»ºå¸¦æ ‡è®°çš„æ–‡æœ¬)
        if corrected_text != clean_text or clean_text != original_text:
            # é‡æ–°æ„å»ºå¸¦æ ‡è®°çš„æ–‡æœ¬(ä¿ç•™åŸå§‹æ ‡è®°)
            # æå–åŸå§‹æ ‡è®°
            tags = re.findall(r'<\|[^|]+\|>', original_text)
            if tags:
                # é‡æ–°ç»„åˆ: æ ‡è®° + ä¿®æ­£åçš„æ–‡æœ¬
                new_text_with_tags = ''.join(tags) + corrected_text
            else:
                new_text_with_tags = corrected_text
            
            logger.info(f"[ASRé”™è¯¯ä¿®æ­£] åŸæ–‡: '{original_text}'")
            logger.info(f"[ASRé”™è¯¯ä¿®æ­£] æ¸…ç†: '{clean_text}'")
            logger.info(f"[ASRé”™è¯¯ä¿®æ­£] ä¿®æ­£: '{corrected_text}'")
            if corrections:
                logger.info(f"[ASRé”™è¯¯ä¿®æ­£] ä¿®æ­£è¯¦æƒ…: {corrections}")
            
            result[0]['text'] = new_text_with_tags
            result[0]['original_text'] = original_text  # ä¿ç•™åŸå§‹æ–‡æœ¬
            result[0]['corrections'] = corrections  # ä¿å­˜ä¿®æ­£è®°å½•
        
        # æœ€ç»ˆé•¿åº¦æ£€æŸ¥
        if config.filter_noise_words and len(corrected_text.strip()) < config.min_text_length:
            logger.info(f"[å™ªéŸ³è¿‡æ»¤] æ–‡æœ¬è¿‡çŸ­,ä¸¢å¼ƒ: '{corrected_text}'")
            return None
    
    return result

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.exception_handler(Exception)
async def custom_exception_handler(request: Request, exc: Exception):
    logger.error("Exception occurred", exc_info=True)
    if isinstance(exc, HTTPException):
        status_code = exc.status_code
        message = exc.detail
        data = ""
    elif isinstance(exc, RequestValidationError):
        status_code = HTTP_422_UNPROCESSABLE_ENTITY
        message = "Validation error: " + str(exc.errors())
        data = ""
    else:
        status_code = 500
        message = "Internal server error: " + str(exc)
        data = ""

    return JSONResponse(
        status_code=status_code,
        content=TranscriptionResponse(
            code=status_code,
            msg=message,
            data=data
        ).model_dump()
    )

# Define the response model
class TranscriptionResponse(BaseModel):
    code: int
    info: str
    data: str
    client: str | None = None
    speaker: str | None = None  # è¯´è¯äººæ ‡è¯†

@app.websocket("/ws/transcribe")
async def websocket_endpoint(websocket: WebSocket):
    client_id = None
    try:
        query_params = parse_qs(websocket.scope['query_string'].decode())
        sv = query_params.get('sv', ['false'])[0].lower() in ['true', '1', 't', 'y', 'yes']
        lang = query_params.get('lang', ['auto'])[0].lower()
        # ä¼˜å…ˆä½¿ç”¨è¯·æ±‚å‚æ•°ä¸­çš„ client_idï¼Œå¦åˆ™å›é€€åˆ° IP:ç«¯å£
        client_id = query_params.get('client_id', [None])[0]
        if not client_id and websocket.client:
            client_id = f"{websocket.client.host}:{websocket.client.port}"
        logger.info(f"[client] å»ºç«‹è¿æ¥ï¼Œclient_id={client_id}")
        
        await websocket.accept()
        chunk_size = int(config.chunk_size_ms * config.sample_rate / 1000)
        audio_buffer = np.array([], dtype=np.float32)
        audio_vad = np.array([], dtype=np.float32)

        cache = {}
        cache_asr = {}
        # è¯´è¯äººå£°çº¹ç‰¹å¾å­—å…¸ {speaker_id: embedding}
        speaker_embeddings = {}
        # å½“å‰è¯´è¯äººID
        current_speaker = None
        # è®°å½•è¯­éŸ³æ®µçš„èµ·å§‹æ—¶é—´æˆ³
        segment_start_time = None
        last_vad_beg = last_vad_end = -1
        offset = 0
        # ç”¨äºä¸Šä¸‹æ–‡ä¿®æ­£çš„å‰ä¸€å¥æ–‡æœ¬
        prev_text = ""
        
        buffer = b""
        while True:
            data = await websocket.receive_bytes()
            # logger.info(f"received {len(data)} bytes")

            
            buffer += data
            if len(buffer) < 2:
                continue
                
            audio_buffer = np.append(
                audio_buffer, 
                np.frombuffer(buffer[:len(buffer) - (len(buffer) % 2)], dtype=np.int16).astype(np.float32) / 32767.0
            )
            
            # with open('buffer.pcm', 'ab') as f:
            #     logger.debug(f'write {f.write(buffer[:len(buffer) - (len(buffer) % 2)])} bytes to `buffer.pcm`')
                
            buffer = buffer[len(buffer) - (len(buffer) % 2):]
   
            while len(audio_buffer) >= chunk_size:
                chunk = audio_buffer[:chunk_size]
                audio_buffer = audio_buffer[chunk_size:]
                audio_vad = np.append(audio_vad, chunk)
                
                # with open('chunk.pcm', 'ab') as f:
                #     logger.debug(f'write {f.write(chunk)} bytes to `chunk.pcm`')
                    
                # æ—§çš„ sv å‚æ•°éªŒè¯é€»è¾‘å·²ç§»é™¤ï¼Œç°åœ¨ç»Ÿä¸€ä½¿ç”¨ identify_speaker() è¿›è¡Œè¯´è¯äººè¯†åˆ«

                res = model_vad.generate(input=chunk, cache=cache, is_final=False, chunk_size=config.chunk_size_ms)
                # logger.info(f"vad inference: {res}")
                if len(res[0]["value"]):
                    vad_segments = res[0]["value"]
                    for segment in vad_segments:
                        if segment[0] > -1: # speech begin
                            last_vad_beg = segment[0]
                            if segment_start_time is None:
                                segment_start_time = time.time()
                                start_sample = int(max(0.0, (segment[0] - offset)) * config.sample_rate / 1000)
                                logger.info(f"[segment] æ£€æµ‹åˆ°è¯­éŸ³æ®µèµ·ç‚¹ï¼Œèµ·å§‹é‡‡æ ·ç‚¹={start_sample}ï¼Œæ—¶é—´æˆ³={segment_start_time:.3f}")                           
                        if segment[1] > -1: # speech end
                            last_vad_end = segment[1]
                        if last_vad_beg > -1 and last_vad_end > -1:
                            last_vad_beg -= offset
                            last_vad_end -= offset
                            offset += last_vad_end
                            beg = int(last_vad_beg * config.sample_rate / 1000)
                            end = int(last_vad_end * config.sample_rate / 1000)
                            logger.info(f"[vad segment] audio_len: {end - beg}")
                            
                            # è¯´è¯äººè¯†åˆ«
                            segment_audio = audio_vad[beg:end]
                            speaker_id, is_new_speaker = identify_speaker(
                                segment_audio, 
                                speaker_embeddings, 
                                config.sd_thr
                            )
                            
                            # å¦‚æœè¯†åˆ«åˆ°æ–°è¯´è¯äºº,å‘é€é€šçŸ¥
                            if is_new_speaker and speaker_id is not None:
                                try:
                                    new_speaker_response = TranscriptionResponse(
                                        code=4,
                                        info="new_speaker_detected",
                                        data=speaker_id,
                                        client=client_id,
                                        speaker=speaker_id
                                    )
                                    logger.info(f"[client] å‘å®¢æˆ·ç«¯å‘é€ï¼š{new_speaker_response.model_dump()}")
                                    await websocket.send_json(new_speaker_response.model_dump())
                                except Exception as e:
                                    logger.debug(f"send new_speaker event failed: {e}")
                            
                            current_speaker = speaker_id
                            
                            # æ‰§è¡Œ ASR è¯†åˆ«(å¯ç”¨é”™è¯¯ä¿®æ­£å’Œé™å™ª)
                            result = asr(
                                segment_audio, 
                                lang.strip(), 
                                cache_asr, 
                                use_itn=True,
                                prev_text=prev_text,
                                enable_correction=config.enable_error_correction,
                                enable_denoise=config.enable_audio_denoise
                            )
                            segment_elapsed_ms = None
                            if segment_start_time is not None:
                                segment_elapsed_ms = (time.time() - segment_start_time) * 1000
                            audio_vad = audio_vad[end:]
                            last_vad_beg = last_vad_end = -1
                            segment_start_time = None
                            logger.info("[segment] è¯­éŸ³æ®µç»“æŸï¼Œå·²é‡ç½®çŠ¶æ€")
                            if segment_elapsed_ms is not None:
                                logger.info(f"[segment] è¯­éŸ³æ®µæ€»è€—æ—¶ï¼š{segment_elapsed_ms:.2f} æ¯«ç§’")
                            
                            # æ£€æŸ¥ ASR ç»“æœæ˜¯å¦æœ‰æ•ˆ(å¯èƒ½è¢«å™ªéŸ³è¿‡æ»¤å™¨ä¸¢å¼ƒ)
                            if result is None:
                                logger.info("[segment] ASRç»“æœä¸ºç©º(å·²è¢«å™ªéŸ³è¿‡æ»¤),è·³è¿‡æ­¤æ®µ")
                                continue
                            
                            logger.info(f"asr response: {result}")
                            
                            # æ›´æ–°å‰ä¸€å¥æ–‡æœ¬(ç”¨äºä¸‹ä¸€æ¬¡ä¸Šä¸‹æ–‡ä¿®æ­£)
                            if 'text' in result[0]:
                                prev_text = result[0]['text']
                            
                            response = TranscriptionResponse(
                                code=0,
                                info=json.dumps(result[0], ensure_ascii=False),
                                data=format_str_v3(result[0]['text']),
                                client=client_id,
                                speaker=current_speaker  # æ·»åŠ è¯´è¯äººä¿¡æ¯
                            )
                            logger.info(f"[client] å‘å®¢æˆ·ç«¯å‘é€ï¼š{response.model_dump()}")
                            await websocket.send_json(response.model_dump())
                                
                        # logger.debug(f'last_vad_beg: {last_vad_beg}; last_vad_end: {last_vad_end} len(audio_vad): {len(audio_vad)}')

    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected, client_id={client_id}")
    except Exception as e:
        logger.error(f"Unexpected error: {e}\nCall stack:\n{traceback.format_exc()}")
        await websocket.close()
    finally:
        audio_buffer = np.array([], dtype=np.float32)
        audio_vad = np.array([], dtype=np.float32)
        cache.clear()
        logger.info(f"Cleaned up resources after WebSocket disconnect, client_id={client_id}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run the FastAPI app with a specified port.")
    parser.add_argument('--port', type=int, default=27100, help='Port number to run the FastAPI app on.')
    # parser.add_argument('--certfile', type=str, default='path_to_your_SSL_certificate_file.crt', help='SSL certificate file')
    # parser.add_argument('--keyfile', type=str, default='path_to_your_SSL_certificate_file.key', help='SSL key file')
    args = parser.parse_args()
    # uvicorn.run(app, host="0.0.0.0", port=args.port, ssl_certfile=args.certfile, ssl_keyfile=args.keyfile)
    uvicorn.run(app, host="0.0.0.0", port=args.port)
